<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Caching vs Database Replication Strategies Based on Data Workload</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/projects.css">
    <link rel="stylesheet" href="css/demo.css">
    <link rel="stylesheet" href="css/profiles.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.10/css/all.css" integrity="sha384-+d0P83n9kaQMCwj8F4RJB66tzIwOKmrdb46+porD/OvrJ+37WqIM7UoBtwHO6Nlg" crossorigin="anonymous">
  </head>
  <body>
    <div class="content">
      <div class="card" id="about">
        <div class="col-md-12 col-xs-12">
          <h1>Caching vs Database Replication Strategies Based on Data Workload</h1>
          <h2 class="colorful">Team Members</h2>
          <div class="profile-container">
            <div class="profile">
              <img src="img/andrew.jpeg" alt="picture">
              <h1>Andrew Wong</h1>
              <h3>CS '19 BS</h3>
              <div class="social">
                <a href="https://github.com/andrewwong97/"><i class="fab fa-github"></i></a>
              </div>
            </div>
            <div class="profile">
              <img src="https://avatars1.githubusercontent.com/u/17332287?s=460&v=4" alt="picture">
              <h1>Ryan Demo</h1>
              <h3>CS, EE '18 BS, CS '19 MS</h3>
              <div class="social">
                <a href="https://github.com/ryandemo/"><i class="fab fa-github"></i></a>
              </div>
            </div>
            <div class="profile">
              <img src="img/ben.jpg" alt="picture">
              <h1>Benjamin Hoertnagl-Pereira</h1>
              <h3>ECE '18 BS, CS '19 MS</h3>
              <div class="social">
                <a href="https://github.com/bpereira615"><i class="fab fa-github"></i></a>
              </div>
            </div>
            <div class="profile">
              <img src="https://avatars2.githubusercontent.com/u/6342492?s=460&v=4" alt="picture">
              <h1>Daniel Sohn </h1>
              <h3>CS, AMS '20 BS</h3>
              <div class="social">
                <a href="https://github.com/dsohn45/"><i class="fab fa-github"></i></a>
              </div>
            </div>
          </div>
        </div>
        <h3>Problem Statement</h3>
        <p>We are looking to investigate strategies for database caching and replication depending on the data workload. Specifically, for a tenant in a datacenter that has to compute on large amounts of uniformly sampled data queried from a database, where first read time can add latency, which combination of local caching and database replication minimizes job compute times?</p>
        <h3>Experiment</h3>
        <p>Our baseline will measure job time using one database node and 32 compute nodes all sending it queries with no compute node local caches. The database node will have an in-memory integrated cache.</p>
        <p>The independent variables are:</p>
        <ul>
          <li><p>Data compute workload: randomly uniformly sampled, sequential</p></li>
          <li><p>Number of jobs per compute node: 32</p></li>
          <li><p>Database size: 4 GB, 16 GB, 64 GB</p></li>
          <li><p>Number of shards: 1, 2, 4, 8</p></li>
          <li><p>Number of replicas per shard: 1, 2, 4, 8</p></li>
          <li><p>Size of local caches for queried data on compute nodes: 0 GB, 0.5 GB, 1 GB, 2 GB</p></li>
        </ul>
        <p>The measured dependent variables are:</p>
        <ul>
          <li><p>Time for job completion</p></li>
          <li><p>CPU and memory utilization per compute node and per database node</p></li>
        </ul>
        <p>From all permutations, we will look at results to determine best practices for caching and/or replication depending on mainly the data compute workload, and analyzing the performance results of each strategy.</p>
        <p>If the previous results prove conclusive, we will develop a simple query load balancer to that dynamically adjusts the amount of database nodes containing shards/replicas based on heuristics from static results, and evaluate its performance compared to the static amount of nodes.</p>
        <a href="https://github.com/andrewwong97/cloud-computing"><button class="slide-deck"><i class="fab fa-github" style="color:#fff;margin-right:7px;"></i>Code</button></a>
        <h3>Timeline</h3>
        <ul>
          <li><p>March 4: Project Proposal</p></li>
          <li><p>March 16: Literature Review</p></li>
          <li><p>March 23: Problem Refinement</p></li>
          <li><p>March 30: Checkpoint 1</p></li>
          <li><p>April 6: Experiment Execution</p></li>
          <li><p>April 13: Checkpoint 2</p></li>
          <li><p>April 20: Experiment Execution, Midterm Presentation</p></li>
          <li><p>April 27: Stretch Goals - Dynamic Replication</p></li>
          <li><p>May 4: Paper Completion</p></li>
        </ul>
        <h3>Existing Work</h3>
        <a href="http://www.pdl.cmu.edu/PDL-FTP/CloudComputing/p236-xiao-SoCC15.pdf">ShardFS vs. IndexFS: Replication vs. Caching Strategies for Distributed Metadata Management in Cloud Storage Systems</a>
        <p>The rapid growth of cloud storage systems calls for fast and scalable namespace processing. While few commercial file systems offer anything better than federating individually non-scalable namespace servers, a recent academic file system, IndexFS, demonstrates scalable namespace processing based on client caching of directory entries and permissions (directory lookup state) with no per-client state in servers. In this paper we explore explicit replication of directory lookup state in all servers as an alternative to caching this information in all clients. Both eliminate most repeated RPCs to different servers in order to resolve hierarchical permission tests. Our realization for server replicated directory lookup state, ShardFS, employs a novel file system specific hybrid optimistic and pessimistic concurrency control favoring single object transactions over distributed transactions. Our experimentation suggests that if directory lookup state mutation is a fixed fraction of operations (strong scaling for metadata), server replication does not scale as well as client caching, but if directory lookup state mutation is proportional to the number of jobs, not the number of processes per job, (weak scaling for metadata), then server replication can scale more linearly than client caching and provide lower 70 percentile response times as well.</p>
        <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.2100&rep=rep1&type=pdf">Analysis of Caching and Replication Strategies for Web Applications</a>
        <p>Replication and caching mechanisms are often employed to enhance the performance of Web applications. In this article, we present a qualitative and quantitative analysis of state-of-the-art replication and caching techniques used to host Web applications. Our analysis shows that the selection of best mechanism is heavily dependant on the data workload and requires careful analysis of the application characteristics. To this end, we propose a technique that may enable future Web practitioners to compare the performance of different caching/replication mechanisms.</p>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5795483/pdf/sensors-18-00222.pdf">Replication Strategy for Spatiotemporal Data Based on Distributed Caching System</a>
        <p>The replica strategy in distributed cache can effectively reduce user access delay and improve system performance. However, developing a replica strategy suitable for varied application scenarios is still quite challenging, owing to differences in user access behavior and preferences. In this paper, a replication strategy for spatiotemporal data (RSSD) based on a distributed caching system is proposed. By taking advantage of the spatiotemporal locality and correlation of user access, RSSD mines high popularity and associated files from historical user access information, and then generates replicas and selects appropriate cache node for placement. Experimental results show that the RSSD algorithm is simple and efficient, and succeeds in significantly reducing user access delay.</p>
        <h3>Extra Notes</h3>
        <p>Database sharding and replication best practices for when data is poorly cacheable or requires fast first reads, and example applications that would use this paradigm.</p>
        <p>Cloud providers that offer multi-tenant services must handle compute hotspots reliably in order to optimize resource usage. Usually the problem is that the server lacks the CPU/memory to execute all the queries, or there is a bandwidth issue. Even if these are hardware limitations and not necessarily database dependent, it can be solved by sharding/replication either by dividing up the queries to different shards or moving a copy of the database closer. One approach to handle dynamic compute-heavy localities relying on the same data is via distributed database sharding.  For example, compute-heavy jobs requiring access to the same data shards may be bottlenecked by database reads, where network congestion (bandwidth) or CPU can be limiting factors of how fast requests are processed.</p>
        <p>To have enough copies of relevant data to balance the compute load across multiple nodes, the database can be replicated dynamically. It is the conditions under which replication should occur and the extent to which it should occur that we are interested in.</p>
        <p>In context of the CAP theorem, there may be multiple optimal replication strategies based on the priorities of the distributed database. For example, given different loads such as read-heavy, mixed r/w, write-heavy operations, caching might be better in read-heavy situations, while sharding might be better when the data is updated frequently. </p>
        <h3>Checkpoint 1 Status</h3>
        <ul>
          <li><p>Analysis of existing systems - Andrew, Ryan, Ben, Daniel</p></li>
          <li><p>Experiment specification - Ryan, Daniel</p></li>
          <li><p>Google Cloud VM configuration - Andrew</p></li>
          <li><p>Project homepage - Andrew, Ben</p></li>
        </ul>
        <h3>Next Steps</h3>
        <ul>
          <li>Google Cloud network configuration - multiple nodes on same subnet</li>
          <li>Metrics automation - job time, CPU and memory utilization</li>
          <li>Workload specification - chained MapReduce/Hadoop</li>
          <li>Experiment execution - independently alter variables</li>
          <li>Results analysis - chaching vs replication tradeoff boundary</li>
          <li>Presentation creation - summarize progress</li>
        </ul>
        <!-- <a href="img/Final Pres.pdf"><button class="slide-deck">Slide Deck PDF</button></a> -->
        
      </div>
      <!-- <div class="card emo">
        <div class="description">
          <h1>Repository</h1>
          <a href="https://github.com/andrewwong97/cloud-computing"
             class="btn-github"
          >
            Github <i class="fab fa-github"></i>
          </a>
          <h2>Includes how to build the system</h2>
          <a href="https://github.com/andrewwong97/cloud-computing"><button class="btn-more">Demo</button></a>
        </div>
        <div class="preview">
          <img src="https://user-images.githubusercontent.com/7339169/55187736-275b6980-5170-11e9-8d45-4c9a5d0e0d41.png">
        </div>
      </div> -->
    </div>
  </body>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js"></script>
</html>